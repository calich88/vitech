{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autograd: T√≠nh ƒë·∫°o h√†m t·ª± ƒë·ªông\n",
    "===================================\n",
    "\n",
    "V·ªÅ m·∫∑t to√°n h·ªçc th√¨ m·∫°ng neural c√≥ th·ªÉ ƒë∆∞·ª£c xem nh∆∞ m·ªôt h√†m to√°n h·ªçc ph·ª©c t·∫°p, v√† vi·ªác t√≠nh ƒë·∫°o h√†m c·ªßa n√≥ l√† r·∫•t quan tr·ªçng khi hu·∫•n luy·ªán m·∫°ng neural.\n",
    "\n",
    "V√¨ v·∫≠y ``autograd`` hay ch·ª©c nƒÉng t√≠nh ƒë·∫°o h√†m t·ª± ƒë·ªông l√† m·ªôt ch·ª©c nƒÉng v√¥ c√πng quan tr·ªçng c·ªßa Pytorch. N√≥i ng·∫Øn g·ªçn, th√¨ ``autograd`` gi√∫p ta t√≠nh ƒë∆∞·ª£c gi√° tr·ªã ƒë·∫°o h√†m t·∫°i c√°c ƒëi·ªÉm c·ª• th·ªÉ v·ªõi h√†m s·ªë ƒë∆∞·ª£c t·∫°o ra t·ª´ m·ªçi ph√©p to√°n tr√™n Tensor m√† kh√¥ng c·∫ßn ph·∫£i bi·∫øt c√¥ng th·ª©c ch√≠nh x√°c."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nh·∫Øc l·∫°i v·ªÅ ƒë·∫°o h√†m\n",
    "--------\n",
    "\n",
    "ƒê·∫°o h√†m c·ªßa m·ªôt h√†m s·ªë m√¥ t·∫£ s·ª± bi·∫øn thi√™n c·ªßa m·ªôt h√†m s·ªë t·∫°i m·ªôt ƒëi·ªÉm, v√≠ d·ª• \n",
    "cho h√†m s·ªë $y =3x^2$ th√¨ ƒë·∫°o h√†m $y'=6x$.\n",
    "T·∫°i ƒëi·ªÉm c·ª• th·ªÉ $x = 5$, ta c√≥ $y = 75$ v√† $y' = 30$ (gi·∫£i th√≠ch n√¥m na l√†, khi x thay ƒë·ªïi 1 ƒë∆°n v·ªã, th√¨ y thay ƒë·ªïi 30 ƒë∆°n v·ªã, trong gi·ªõi h·∫°n nh·ªè quanh ƒëi·ªÉm $x=5$). V√≠ d·ª• t√≠nh to√°n ƒë∆°n gi·∫£n n√†y c√≥ th·ªÉ ƒë∆∞·ª£c m√¥ t·∫£ trong pytorch nh∆∞ sau:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([75.], grad_fn=<ThMulBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Kh·ªüi t·∫°o ƒëi·ªÉm x = 5\n",
    "x = torch.tensor([5.0], requires_grad=True)\n",
    "y = 3 * x * x\n",
    "# T√≠nh y t·∫°i ƒëi·ªÉm x = 5\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([30.])\n"
     ]
    }
   ],
   "source": [
    "# T√≠nh ƒë·∫°o h√†m\n",
    "y.backward()\n",
    "# In ra gi√° tr·ªã ƒë·∫°o h√†m y' = dy/dx t·∫°i ƒëi·ªÉm x = 5\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nh∆∞ v·∫≠y l√† pytorch gi√∫p ta t√≠nh ƒë∆∞·ª£c gi√° tr·ªã c·ªßa ƒë·∫°o h√†m $y'$ t·∫°i m·ªôt ƒëi·ªÉm x m√† kh√¥ng c·∫ßn d√πng c√¥ng th·ª©c ƒë·∫°o h√†m $x^n = nx^{n-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta c√≥ th·ªÉ m·ªü r·ªông ra vi·ªác t√≠nh ƒë·∫°o h√†m v·ªõi h√†m nhi·ªÅu bi·∫øn v·ªõi v√≠ d·ª• sau, cho h√†m s·ªë $z = 5x^3 + 2y^2$, ta c√≥ ƒë·∫°o h√†m ri√™ng $\\frac{dz}{dx}=15x^2$, v√† $\\frac{dz}{dy}=4y$. T·∫°i ƒëi·ªÉm $(x = 7, y = 8)$ ta c√≥ $z = 1843$ v√† $\\frac{dz}{dx}=735$, $\\frac{dz}{dy}=32$\n",
    "\n",
    "V√≠ d·ª• n√†y ƒë∆∞·ª£c m√¥ t·∫£ trong pytorch nh∆∞ sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1843.], grad_fn=<ThAddBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Kh·ªüi t·∫°o ƒëi·ªÉm x = 5\n",
    "x = torch.tensor([7.0], requires_grad=True)\n",
    "y = torch.tensor([8.0], requires_grad=True)\n",
    "z = 5 * x * x * x + 2 * y * y\n",
    "# T√≠nh z t·∫°i ƒëi·ªÉm (x = 7, y = 8)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([735.])\n"
     ]
    }
   ],
   "source": [
    "# T√≠nh ƒë·∫°o h√†m\n",
    "z.backward()\n",
    "# In ra gi√° tr·ªã ƒë·∫°o h√†m dz/dx\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([32.])\n"
     ]
    }
   ],
   "source": [
    "# In ra gi√° tr·ªã ƒë·∫°o h√†m dz/dy\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L∆∞u √Ω trong c√°c v√≠ d·ª• tr√™n, khi khai b√°o c√°c tensor nh∆∞ x, y v√† sau n√†y c·∫ßn t√≠nh ƒë·∫°o h√†m, ta c·∫ßn th√™m thu·ªôc t√≠nh `requires_grad=True` ƒë·ªÉ pytorch ghi nh·ªõ c√°c ph√©p to√°n tr√™n c√°c tensor n√†y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ƒê·∫°o h√†m c·ªßa Tensor\n",
    "--------\n",
    "·ªû c√°c v√≠ d·ª• tr√™n ƒë√¢y, ta ƒë√£ khai b√°o x, y nh∆∞ c√°c ƒë·∫°i l∆∞·ª£ng v√¥ h∆∞·ªõng (Tensor v·ªõi k√≠ch th∆∞·ªõc 1), v·∫≠y trong tr∆∞·ªùng h·ª£p t·ªïng qu√°t th√¨ sao? Ta h√£y quay l·∫°i v√≠ d·ª• ƒë·∫ßu ti√™n nh∆∞ng v·ªõi x l√† 1 ma tr·∫≠n 2x2:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 48.],\n",
      "        [75., 12.]], grad_fn=<ThMulBackward>)\n",
      "tensor([[18., 24.],\n",
      "        [30., 12.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[3.0, 4.0], [5.0, 2.0]], requires_grad=True)\n",
    "y = 3 * x * x\n",
    "print(y)\n",
    "y = y.sum()\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L∆∞u √Ω, trong v√≠ d·ª• tr√™n ƒë√¢y, $x*x$ ch·ªâ ph√©p l·∫•y t√≠ch hai ma tr·∫≠n theo t·ª´ng ph√¢n t·ª≠, ch·ª© kh√¥ng ph·∫£i l√† ph√©p nh√¢n ma tr·∫≠n. Ta th·∫•y trong tr∆∞·ªùng h·ª£p n√†y, k·∫øt qu·∫£ ƒë·∫°o h√†m $y'$ ch·ªâ l√† m·ªü r·ªông c·ªßa tr∆∞·ªùng h·ª£p ƒë·∫°i l∆∞·ª£ng v√¥ h∆∞·ªõng; m·ªói ph·∫ßn t·ª≠ c·ªßa $y'$ l√† gi√° tr·ªã ƒë·∫°o h√†m t·∫°i ƒëi·ªÉm t∆∞∆°ng ·ª©ng tr√™n ma tr·∫≠n $x$ ban ƒë·∫ßu. Ta h√£y th·ª≠ thay $x*x$ b·∫±ng ph√©p nh√¢n ma tr·∫≠n (th·ªÉ hi·ªán qua h√†m `torch.mm`) v√† xem gi√° tr·ªã ƒë·∫°o h√†m thay ƒë·ªïi nh∆∞ th·∫ø n√†o. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[87., 60.],\n",
      "        [75., 72.]], grad_fn=<MulBackward>)\n",
      "tensor([[45., 45.],\n",
      "        [39., 39.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[3.0, 4.0], [5.0, 2.0]], requires_grad=True)\n",
    "y = 3 * torch.mm(x, x)\n",
    "print(y)\n",
    "y = y.sum()\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong v√≠ d·ª• tr√™n, gi·∫£ s·ª≠\n",
    "$\n",
    "x = \\left(\\begin{array} \n",
    "\\\\a & b\\\\\n",
    "c & d\n",
    "\\end{array}\\right)\n",
    "$, th√¨ ta s·∫Ω c√≥ $y = 3 * (a^2 + d^2 + ab + ac + bc + bd + cd)$, v√† ƒë·∫°o h√†m ri√™ng $\\frac{dy}{da}=6a + 3b + 3c$, v·ªõi $\n",
    "x = \\left(\\begin{array} \n",
    "\\\\3 & 4\\\\\n",
    "5 & 2\n",
    "\\end{array}\\right)\n",
    "$ th√¨  $\\frac{dy}{da}=45$\n",
    "\n",
    "Ghi ch√∫: ``autograd`` c≈©ng ho·∫°t ƒë·ªông ƒë∆∞·ª£c khi y kh√¥ng ph·∫£i l√† ƒë·∫°i l∆∞·ª£ng v√¥ h∆∞·ªõng; tuy nhi√™n ƒëi·ªÅu n√†y n·∫±m ngo√†i ph·∫°m vi c·ªßa b√†i n√†y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autograd v·ªõi h√†m h·ª£p\n",
    "--------\n",
    "Gi√° tr·ªã c·ªßa autograd th·ªÉ hi·ªán r√µ th√™m v·ªõi m·ªôt h√†m s·ªë h·ª£p ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a qua nhi·ªÅu b∆∞·ªõc (ƒë·∫∑c bi·ªát hay √°p d·ª•ng trong m·∫°ng Neural khi k·∫øt qu·∫£ l√† s·ª± k·∫øp h·ª£p c·ªßa nhi·ªÅu l·ªõp Neural). V√≠ d·ª• $ùë¶=2ùë•^3$ v√† $z=5y^2$. N·∫øu t√≠nh ƒë·∫°o h√†m th·ªß c√¥ng ta c√≥ th·ªÉ d√πng c√¥ng th·ª©c $\\frac{dz}{dx}=\\frac{dz}{dy}\\frac{dy}{dx}=10y6x^2=120x^5$. T·∫°i $x=2$ th√¨ $\\frac{dz}{dx}=3840$. V√≠ d·ª• n√†y ƒë∆∞·ª£c m√¥ t·∫£ qua pytorch nh∆∞ sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([16.], grad_fn=<ThMulBackward>)\n",
      "tensor([1280.], grad_fn=<ThMulBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Kh·ªüi t·∫°o ƒëi·ªÉm x = 2\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "y = 2 * x * x * x\n",
    "z = 5 * y * y\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3840.])\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autograd ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o\n",
    "--------\n",
    "Ta c√≥ th·ªÉ gi·∫£i th√≠ch c∆° ch·∫ø ho·∫°t ƒë·ªông c·ªßa autograd t·ª´ v√≠ d·ª• ƒë∆°n gi·∫£n tr√™n ƒë√¢y. Autograd s·∫Ω x√¢y d·ª±ng h√†m s·ªë ƒë√≠ch d∆∞·ªõi d·∫°ng m·ªôt ƒë·ªì th·ªã t√≠nh to√°n (computation graph) qua t·ª´ng b∆∞·ªõc, v√† c≈©ng √°p d·ª•ng c√¥ng th·ª©c $\\frac{dz}{dx}=\\frac{dz}{dy}\\frac{dy}{dx}$ ƒë·ªÉ t√≠nh ng∆∞·ª£c ƒë·∫°o h√†m. L∆∞u √Ω l√† autograd gi√∫p ta t√≠nh gi√° tr·ªã c·ª• th·ªÉ c·ªßa ƒë·∫°o h√†m t·∫°i m·ªôt ƒëi·ªÉm x√°c ƒë·ªãnh n√™n c√¥ng th·ª©c n√†y s·∫Ω √°p d·ª•ng tr√™n gi√°i tr·ªã c·ª• th·ªÉ, ch·ª© kh√¥ng ph·∫£i tr√™n c√¥ng th·ª©c t·ªïng qu√°t (symbolic differentiation). Trong v√≠ d·ª• tr√™n, ƒë·∫ßu ti√™n autograd s·∫Ω t√≠nh $\\frac{dz}{dy} = 160$, sau ƒë√≥ t√≠nh ƒë∆∞·ª£c $\\frac{dy}{dx} = 24$, v√† cu·ªëi c√πng $\\frac{dz}{dx}=3840$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
